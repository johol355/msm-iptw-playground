{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginal structural models, frequentist approach\n",
    "## IPTW based MSM\n",
    "This is a python conversion of Andrew Heiss' blog post on IPTW based MSM's here: https://www.andrewheiss.com/blog/2020/12/03/ipw-tscs-msm/\n",
    "Andrew's generated data will be used. The dataset simulates the effects of the 6-hour working day policy (binary treatment) on happiness in several (fake) countries. The underlying DAG is this: https://www.andrewheiss.com/blog/2020/12/03/ipw-tscs-msm/index_files/figure-html/dag-complex-1.png\n",
    "\n",
    "Here, our goal is to get an estimate for the instantaneous (same year) effect on happiness of having instituted a 6-hour work day vs not having insituted this policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "After loading the data, a preprocessing step to filter out countries that never adopt the new policies. This is because of math issues when treatment remains unchanged. This could be helped with zero-inflated modeling of the IPW instead of plain logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://www.andrewheiss.com/blog/2020/12/03/ipw-tscs-msm/happiness_data.csv')\n",
    "policy_data = data[data[\"country\"].isin(data[data[\"policy\"] == 1].country)].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary treatment MSM/IPTW\n",
    "### How and why IPTW works\n",
    "Nicely explained here: https://www.youtube.com/watch?v=PfLYPt9ur4g\n",
    "\n",
    "If $Z$ is a set of variables that completely explain the confounding, then we have conditional exchangeability given $Z$. I.e. within levels of $Z$ the observation of treatment groups $A$ and their respective outcomes can be used to easily calculate the potential outcomes. Imagine a situation with only binary confounds, treatments and outcomes. To calculate the treatment effect we need to calculate the outcomes if all individuals recieved treatment or not, within groups.\n",
    "\n",
    "So, for example, in group $Z=0$ we need to calculate the number of successes/failures if all 40 did get the treatment. Since 0.7 of the treated see success, we would end up with another 7 successes and three failures. We get this exact result if we just multiply the number of successes/failures in the treatment group by multiplying the inverse probability of receiving treatment within this strata of $Z$! The same is applied to group $Z=1$.\n",
    "\n",
    "<img src='iptw1.png'>\n",
    "\n",
    "The same logic applies when calculating the outcomes had all individuals not been treated:\n",
    "\n",
    "<img src='iptw2.png'>\n",
    "\n",
    "If we now add up the weighted populations of treated and untreated, we end up with a \"pseudopopulation\". One can see that it is larger (n=200) and that the probabilty of treatment is equal between groups. (Note: there could of course remain differences in treatment effect across groups, but this is true for randomized experiments as well!)\n",
    "\n",
    "<img src='iptw3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Calculating IPTW for binary treatment in time series\n",
    "$\\text{unstabilized binary IPW}_{it} = \\prod_{t=1}^{t} \\frac{1}{P(X_{it} | \\bar{X}_{i,t-1}, Y_{i,t-1}, C_{it}, V_{i})}$, where\n",
    "\n",
    " - ${i}$ is the individual country\n",
    " - ${t}$ it the timestep, ${X_{it}}$ is an observed treatment assignment for ${i}$ at ${t}$\n",
    " - $\\bar{X}_{i,t-1}$ is the observed treatment assignments for ${i}$ at ${t-1}$\n",
    " - ${Y}_{i,t-1}$ is the observed outcome ${i}$ at ${t-1}$, $C_{it}$ are the time varying confounders for ${i}$ at ${t}$\n",
    " - $V_{i}$ are the time invariant (constant) confounders for ${i}$\n",
    "\n",
    "\n",
    "<b>Read as:</b> \"inverse probability of treatment given all previous treatment assignments, the outcome of interest at the previous timestep, the current time varying confounders and the constant confounders\"\n",
    "\n",
    "However, these weights need to be stabilized. This is done by a modifying the numerator:\n",
    "\n",
    "$\\text{stabilized binary IPW}_{it} = \\prod_{t=1}^{t} \\frac{P(X_{it} | \\bar{X}_{i,t-1}, V_{i})}{P(X_{it})| \\bar{X}_{i,t-1}, Y_{i,t-1}, C_{it}, V_{i})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recipe for IPTW MSM\n",
    "1. Define the structure of the model (a DAG) \n",
    "2. Define the propensity for treatment function $e(W)$ and fit it\n",
    "3. Calculate the instantaneous IPTW for each datapoint\n",
    "4. Calculate the cumulative IPTW for all datapoints through all timesteps $t$\n",
    "5. Reweight the population and fit the estimator to get the estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#create new dataframe\n",
    "policy_data_weighted = policy_data.copy()\n",
    "\n",
    "#raw propensity scores\n",
    "model_num = smf.glm(\"policy ~ lag_policy + country\", data=policy_data, family=sm.families.Binomial(sm.families.links.logit()))\n",
    "model_den = smf.glm(\"policy ~ log_gdp_cap + democracy + corruption + lag_happiness_policy + lag_policy + country\", data=policy_data, family=sm.families.Binomial(sm.families.links.logit()))\n",
    "policy_data_weighted[\"propensity_num\"] = model_num.fit().fittedvalues\n",
    "policy_data_weighted[\"propensity_den\"] = model_den.fit().fittedvalues\n",
    "\n",
    "#calculate instantaneous ipw\n",
    "policy_data_weighted[\"propensity_num_outcome\"] = np.where(policy_data_weighted[\"policy\"]==1, policy_data_weighted[\"propensity_num\"], 1-policy_data_weighted[\"propensity_num\"])\n",
    "policy_data_weighted[\"propensity_den_outcome\"] = np.where(policy_data_weighted[\"policy\"]==1, policy_data_weighted[\"propensity_den\"], 1-policy_data_weighted[\"propensity_den\"])\n",
    "policy_data_weighted[\"instant_iptw\"] = policy_data_weighted[\"propensity_num_outcome\"] / policy_data_weighted[\"propensity_den_outcome\"]\n",
    "\n",
    "#calculate actual ipw (cumsum)\n",
    "policy_data_weighted[\"iptw\"] = policy_data_weighted.groupby(\"country\").instant_iptw.cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>vacation_days</th>\n",
       "      <th>policy</th>\n",
       "      <th>happiness_vacation</th>\n",
       "      <th>happiness_policy</th>\n",
       "      <th>log_population</th>\n",
       "      <th>log_gdp</th>\n",
       "      <th>gdp</th>\n",
       "      <th>population</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_policy</th>\n",
       "      <th>lag_happiness_policy</th>\n",
       "      <th>lag_vacation_days</th>\n",
       "      <th>lag_happiness_vacation</th>\n",
       "      <th>propensity_num</th>\n",
       "      <th>propensity_den</th>\n",
       "      <th>propensity_num_outcome</th>\n",
       "      <th>propensity_den_outcome</th>\n",
       "      <th>instant_iptw</th>\n",
       "      <th>iptw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mimim</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>36.9</td>\n",
       "      <td>17.400408</td>\n",
       "      <td>23.080098</td>\n",
       "      <td>1.055745e+10</td>\n",
       "      <td>3.604965e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>12</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.490559e-07</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mimim</td>\n",
       "      <td>2011</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>45.1</td>\n",
       "      <td>40.6</td>\n",
       "      <td>17.446364</td>\n",
       "      <td>23.190996</td>\n",
       "      <td>1.179564e+10</td>\n",
       "      <td>3.774501e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>36.9</td>\n",
       "      <td>12</td>\n",
       "      <td>43.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.210634e-06</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.800002</td>\n",
       "      <td>0.640002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mimim</td>\n",
       "      <td>2012</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>52.7</td>\n",
       "      <td>44.3</td>\n",
       "      <td>17.492320</td>\n",
       "      <td>23.264189</td>\n",
       "      <td>1.269138e+10</td>\n",
       "      <td>3.952009e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>14</td>\n",
       "      <td>45.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.503107e-03</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.992497</td>\n",
       "      <td>0.806048</td>\n",
       "      <td>0.515872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year  vacation_days  policy  happiness_vacation  happiness_policy  \\\n",
       "0   Mimim  2010             12       0                43.2              36.9   \n",
       "1   Mimim  2011             14       0                45.1              40.6   \n",
       "2   Mimim  2012             16       0                52.7              44.3   \n",
       "\n",
       "   log_population    log_gdp           gdp    population  ...  lag_policy  \\\n",
       "0       17.400408  23.080098  1.055745e+10  3.604965e+07  ...           0   \n",
       "1       17.446364  23.190996  1.179564e+10  3.774501e+07  ...           0   \n",
       "2       17.492320  23.264189  1.269138e+10  3.952009e+07  ...           0   \n",
       "\n",
       "   lag_happiness_policy  lag_vacation_days  lag_happiness_vacation  \\\n",
       "0                  36.8                 12                    41.5   \n",
       "1                  36.9                 12                    43.2   \n",
       "2                  40.6                 14                    45.1   \n",
       "\n",
       "   propensity_num  propensity_den  propensity_num_outcome  \\\n",
       "0             0.2    2.490559e-07                     0.8   \n",
       "1             0.2    2.210634e-06                     0.8   \n",
       "2             0.2    7.503107e-03                     0.8   \n",
       "\n",
       "   propensity_den_outcome  instant_iptw      iptw  \n",
       "0                1.000000      0.800000  0.800000  \n",
       "1                0.999998      0.800002  0.640002  \n",
       "2                0.992497      0.806048  0.515872  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_data_weighted.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of ATE\n",
    "With the IPWT calculated, we can estimate the ATE. Here I'll use a simple GLM, whereas Heiss uses a mixed effects model. The latter simply does not work with statsmodels as it will not accept weights. However, the effect of the policy on happiness is very close to the true value 7.6!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_ate_model = smf.glm(\"happiness_policy ~ policy + lag_policy\",\n",
    "                           data = policy_data_weighted,\n",
    "                           freq_weights=policy_data_weighted[\"iptw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>happiness_policy</td> <th>  No. Observations:  </th>   <td>  1380</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 2014.91</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Gaussian</td>     <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>       <td>identity</td>     <th>  Scale:             </th>  <td>  80.223</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th>  <td> -7285.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 09 Nov 2022</td> <th>  Deviance:          </th> <td>1.6164e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:25:43</td>     <th>  Pearson chi2:      </th>  <td>1.62e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>3</td>        <th>  Pseudo R-squ. (CS):</th>   <td>0.2054</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   48.5687</td> <td>    0.471</td> <td>  103.069</td> <td> 0.000</td> <td>   47.645</td> <td>   49.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>policy</th>     <td>    7.8076</td> <td>    0.771</td> <td>   10.128</td> <td> 0.000</td> <td>    6.297</td> <td>    9.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_policy</th> <td>    1.5761</td> <td>    0.654</td> <td>    2.410</td> <td> 0.016</td> <td>    0.294</td> <td>    2.858</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:       happiness_policy   No. Observations:                 1380\n",
       "Model:                            GLM   Df Residuals:                  2014.91\n",
       "Model Family:                Gaussian   Df Model:                            2\n",
       "Link Function:               identity   Scale:                          80.223\n",
       "Method:                          IRLS   Log-Likelihood:                -7285.9\n",
       "Date:                Wed, 09 Nov 2022   Deviance:                   1.6164e+05\n",
       "Time:                        19:25:43   Pearson chi2:                 1.62e+05\n",
       "No. Iterations:                     3   Pseudo R-squ. (CS):             0.2054\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     48.5687      0.471    103.069      0.000      47.645      49.492\n",
       "policy         7.8076      0.771     10.128      0.000       6.297       9.319\n",
       "lag_policy     1.5761      0.654      2.410      0.016       0.294       2.858\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_ate_model.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final thoughts\n",
    "- Python is no good for this type of problems. R has packages such as `lmer` and `ipw` will make your life easier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14bdb3200726c7c15f07af1a48e91911d8ce5614bbcad0cbd23f034220337cd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
