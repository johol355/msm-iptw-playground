{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginal structural models (MSM), frequentist approach\n",
    "## IPTW based MSM ad modum Andrew Heiss\n",
    "This is a python conversion of Andrew Heiss' blog post on IPTW based MSM's here: https://www.andrewheiss.com/blog/2020/12/03/ipw-tscs-msm/\n",
    "Andrew's generated data will be used. The dataset simulates the effects of the 6-hour working day policy (binary treatment) and number of vacation days (cont. treatment) on happiness in several (fake) countries. The underlying DAG is this: https://www.andrewheiss.com/blog/2020/12/03/ipw-tscs-msm/index_files/figure-html/dag-complex-1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and a stupid preprocessing step\n",
    "After loading the data, a preprocessing step to filter out countries that never adopt the new policies. This is because of math issues when treatment remains unchanged. This could be helped with zero-inflated modeling of the IPW instead of plain logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://www.andrewheiss.com/blog/2020/12/03/ipw-tscs-msm/happiness_data.csv')\n",
    "policy_data = data[data[\"country\"].isin(data[data[\"policy\"] == 1].country)].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary treatment MSM/IPTW\n",
    "### Underlying question\n",
    "What is the effect of implementing the 6-hour working day on happiness?\n",
    "### IPTW for binary treatment\n",
    "\n",
    "$\\text{unstabilized binary IPW}_{it} = \\prod_{t=1}^{t} \\frac{1}{P(X_{it} | \\bar{X}_{i,t-1}, Y_{i,t-1}, C_{it}, V_{i})}$, where\n",
    "\n",
    " - ${i}$ is the individual country\n",
    " - ${t}$ it the timestep, ${X_{it}}$ is an observed treatment assignment for ${i}$ at ${t}$\n",
    " - $\\bar{X}_{i,t-1}$ are the observed treatment assignments for ${i}$ <b>up until</b> ${t-1}$\n",
    " - ${Y}_{i,t-1}$ is the observed outcome ${i}$ at ${t-1}$, $C_{it}$ are the time varying confounders for ${i}$ at ${t}$\n",
    " - $V_{i}$ are the time invariant (constant) confounders for ${i}$.\n",
    "\n",
    "\n",
    "<b>Read as:</b> \"inverse probability of treatment given all previous treatment assignments, the outcome of interest at the previous timestep, the current time varying confounders and the constant confounders\"\n",
    "\n",
    "However, these weights need to be stabilized. This is done by a modifying the numerator:\n",
    "\n",
    "$\\text{stabilized binary IPW}_{it} = \\prod_{t=1}^{t} \\frac{P(X_{it} | \\bar{X}_{i,t-1}, V_{i})}{P(X_{it})| \\bar{X}_{i,t-1}, Y_{i,t-1}, C_{it}, V_{i})}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recipe for getting the IPTW\n",
    "1. Define the propensity function $e(W)$\n",
    "2. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#create new dataframe\n",
    "policy_data_weighted = policy_data.copy()\n",
    "\n",
    "#raw propensity scores\n",
    "model_num = smf.glm(\"policy ~ lag_policy + country\", data=policy_data, family=sm.families.Binomial(sm.families.links.logit()))\n",
    "model_den = smf.glm(\"policy ~ log_gdp_cap + democracy + corruption + lag_happiness_policy + lag_policy + country\", data=policy_data, family=sm.families.Binomial(sm.families.links.logit()))\n",
    "policy_data_weighted[\"propensity_num\"] = model_num.fit().fittedvalues\n",
    "policy_data_weighted[\"propensity_den\"] = model_den.fit().fittedvalues\n",
    "\n",
    "#calculate instantaneous ipw\n",
    "policy_data_weighted[\"propensity_num_outcome\"] = np.where(policy_data_weighted[\"policy\"]==1, policy_data_weighted[\"propensity_num\"], 1-policy_data_weighted[\"propensity_num\"])\n",
    "policy_data_weighted[\"propensity_den_outcome\"] = np.where(policy_data_weighted[\"policy\"]==1, policy_data_weighted[\"propensity_den\"], 1-policy_data_weighted[\"propensity_den\"])\n",
    "policy_data_weighted[\"instant_ipw\"] = policy_data_weighted[\"propensity_num_outcome\"] / policy_data_weighted[\"propensity_den_outcome\"]\n",
    "\n",
    "#calculate actual ipw (cumsum)\n",
    "policy_data_weighted[\"ipw\"] = policy_data_weighted.groupby(\"country\").instant_ipw.cumprod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of ATE\n",
    "With the IPWT calculated, we can estimate the ATE. Here I'll use a simple GLM, whereas Heiss uses a mixed effects model. The latter simply does not work with statsmodels as it will not accept weights. However, the effect of the policy on happiness is very close to the true value 7.6!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_ate_model = smf.glm(\"happiness_policy ~ policy + lag_policy\",\n",
    "                           data = policy_data_weighted,\n",
    "                           freq_weights=policy_data_weighted[\"ipw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>happiness_policy</td> <th>  No. Observations:  </th>   <td>  1380</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 2014.91</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Gaussian</td>     <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>       <td>identity</td>     <th>  Scale:             </th>  <td>  80.223</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th>  <td> -7285.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 09 Nov 2022</td> <th>  Deviance:          </th> <td>1.6164e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>17:13:22</td>     <th>  Pearson chi2:      </th>  <td>1.62e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>3</td>        <th>  Pseudo R-squ. (CS):</th>   <td>0.2054</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   48.5687</td> <td>    0.471</td> <td>  103.069</td> <td> 0.000</td> <td>   47.645</td> <td>   49.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>policy</th>     <td>    7.8076</td> <td>    0.771</td> <td>   10.128</td> <td> 0.000</td> <td>    6.297</td> <td>    9.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_policy</th> <td>    1.5761</td> <td>    0.654</td> <td>    2.410</td> <td> 0.016</td> <td>    0.294</td> <td>    2.858</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:       happiness_policy   No. Observations:                 1380\n",
       "Model:                            GLM   Df Residuals:                  2014.91\n",
       "Model Family:                Gaussian   Df Model:                            2\n",
       "Link Function:               identity   Scale:                          80.223\n",
       "Method:                          IRLS   Log-Likelihood:                -7285.9\n",
       "Date:                Wed, 09 Nov 2022   Deviance:                   1.6164e+05\n",
       "Time:                        17:13:22   Pearson chi2:                 1.62e+05\n",
       "No. Iterations:                     3   Pseudo R-squ. (CS):             0.2054\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     48.5687      0.471    103.069      0.000      47.645      49.492\n",
       "policy         7.8076      0.771     10.128      0.000       6.297       9.319\n",
       "lag_policy     1.5761      0.654      2.410      0.016       0.294       2.858\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_ate_model.fit().summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14bdb3200726c7c15f07af1a48e91911d8ce5614bbcad0cbd23f034220337cd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
